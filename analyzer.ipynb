{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer:\n",
    "    def __init__(self, device=None):\n",
    "        if device:\n",
    "            self.device = torch.device(device)\n",
    "        else:\n",
    "            self.device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "        # подгружаем модель\n",
    "        # модель детекции телефонов и похожего на телефоны\n",
    "        self.model_phone_detect = YOLO(\"./weights/best_phone.pt\") \n",
    "        # дополнительный классификатор телефон или что-то иное\n",
    "        self.model_phone_clf = torch.load(\"./weights/model64_1.pt\")\n",
    "        self.model_phone_clf.eval()\n",
    "        self.model_phone_clf.to(\"cpu\")\n",
    "\n",
    "        self.transforms = transform_base = A.Compose([ \n",
    "    A.Resize(64, 64), \n",
    "    A.Normalize(), \n",
    "    ToTensorV2() \n",
    "])\n",
    "\n",
    "        # self.upscale_crop = upscale_crop\n",
    "\n",
    "        \n",
    "        self.colors = [\n",
    "            (),\n",
    "            (),\n",
    "            (0, 0, 255)  # phone\n",
    "        ]\n",
    "\n",
    "        self.KPS = 1  # Target Keyframes Per Second\n",
    "\n",
    "    def predict_video(self, video_path):\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "        hop = round(fps / self.KPS)\n",
    "        curr_frame = 0\n",
    "        curr_second = 0\n",
    "\n",
    "        # число элементов == числу секунд в видео\n",
    "        # 0 - на фрейме ничего нет, 1 - бокс предсказанный на фрейме с макс вероятностью\n",
    "        # телефон\n",
    "        # данные, которые надо записывать во время отработки программы\n",
    "        phone_sec_lst = []\n",
    "\n",
    "        while True:\n",
    "            curr_state = 0  # для phone_sec_lst\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "\n",
    "            # по одному заходу сюда каждую секунду\n",
    "            if curr_frame % hop == 0:\n",
    "                \n",
    "                # пропустим через детектор\n",
    "                res_detect = self.detect_phone(frame)\n",
    "                if res_detect is not None and (len(res_detect[\"boxes\"]) > 0):\n",
    "                    # если детектор нашел что-то, то пропускаем через классификатор\n",
    "                    clf_res = self.clf_phone(res_detect[\"object\"])\n",
    "                    if clf_res:\n",
    "                        curr_state = 1\n",
    "\n",
    "                phone_sec_lst.append(curr_state)\n",
    "\n",
    "                curr_second += 1\n",
    "            \n",
    "            curr_frame += 1\n",
    "        \n",
    "        cap.release()\n",
    "\n",
    "        # изображение обработалось теперь надо провести посекундный анализ\n",
    "        intervals_lst = []\n",
    "        time_sec_counter = 0\n",
    "        phone_frame_counter = 0\n",
    "        print(f\"Sec: {len(phone_sec_lst)}\")\n",
    "\n",
    "        # нету ли тут ошибки???\n",
    "        for item in phone_sec_lst:\n",
    "            if item == 0:\n",
    "                if phone_frame_counter < 3:\n",
    "                    phone_frame_counter = 0\n",
    "                elif phone_frame_counter == 3:\n",
    "                    # записываем конец текущего интервала\n",
    "                    if len(intervals_lst) > 0:\n",
    "                        intervals_lst[-1].append(time_sec_counter)\n",
    "                    else:\n",
    "                        intervals_lst.append([time_sec_counter - 2, time_sec_counter])\n",
    "                    # обнуляем счетчик\n",
    "                    phone_frame_counter = 0\n",
    "                else:\n",
    "                    # записываем конец текущего интервала\n",
    "                    intervals_lst[-1].append(time_sec_counter)\n",
    "                    # обнуляем счетчик\n",
    "                    phone_frame_counter = 0\n",
    "            \n",
    "            else:\n",
    "                if phone_frame_counter < 3:\n",
    "                    phone_frame_counter += 1\n",
    "                elif phone_frame_counter == 3:\n",
    "                    # инициализируем интервал\n",
    "                    intervals_lst.append([time_sec_counter - 3])\n",
    "                    phone_frame_counter += 1\n",
    "                else:\n",
    "                    phone_frame_counter += 1\n",
    "\n",
    "            time_sec_counter += 1\n",
    "\n",
    "        \n",
    "        if len(intervals_lst) > 0 and len(intervals_lst[-1]) == 1:\n",
    "            intervals_lst[-1].append(time_sec_counter)\n",
    "\n",
    "        if len(intervals_lst) > 0:\n",
    "            print(\"Было долгое использование телефона\")\n",
    "            intervals_str = [ \n",
    "            f\"{self.sec2minutes_sec(item[0])} - {self.sec2minutes_sec(item[1])}\"\n",
    "                          for item in intervals_lst\n",
    "                          ]\n",
    "\n",
    "            print(f\"Intervals: {intervals_str}\")\n",
    "        \n",
    "        else:\n",
    "            print(\"Нарушений не выявлено\")\n",
    "\n",
    "    def detect_phone(self, img: np.array):\n",
    "        yolo_results = self.get_yolo_results(img)       \n",
    "\n",
    "        # if not save is None:\n",
    "            # собираем изображение и сохраняем его\n",
    "            # for curr_class, curr_box in  zip(yolo_results[\"class_ids\"], yolo_results[\"boxes\"]):\n",
    "                # (x, y, x2, y2) = curr_box\n",
    "                # cv2.rectangle(img, (x, y), (x2, y2), self.colors[curr_class], 2)\n",
    "            # cv2.imwrite(save, img)\n",
    "\n",
    "        return yolo_results\n",
    "\n",
    "    def get_yolo_results(self, tile):\n",
    "        yolo_results = self.model_phone_detect.predict(source=tile, save=False, save_txt=False, verbose=False)\n",
    "\n",
    "        height, width, channels = tile.shape\n",
    "\n",
    "        # если ничего не путаю, возможен только один проход по циклу\n",
    "        for result in yolo_results:\n",
    "            if result.boxes is not None:\n",
    "                # боксы\n",
    "                bboxes = np.array(result.boxes.xyxyn.cpu(), dtype=\"float\")\n",
    "                bboxes[:, 0] *= width\n",
    "                bboxes[:, 2] *= width\n",
    "                bboxes[:, 1] *= height\n",
    "                bboxes[:, 3] *= height\n",
    "                bboxes = bboxes.astype(int)[:1]\n",
    "\n",
    "                # Get class ids\n",
    "                class_ids = np.array(result.boxes.cls.cpu(), dtype=\"int\")[:1]\n",
    "\n",
    "                # Get scores\n",
    "                scores = np.array(result.boxes.conf.cpu(), dtype=\"float\").round(2)[:1]\n",
    "\n",
    "                # max_object - бокс с максимальным скором, который мы рассматриваем\n",
    "                if len(bboxes) > 0:\n",
    "                    x, y, x2, y2 = bboxes[0]\n",
    "                    max_object = tile[y:y2, x:x2, :]\n",
    "                else:\n",
    "                    max_object = None\n",
    "\n",
    "                return {\n",
    "                    \"boxes\": bboxes,\n",
    "                    \"class_ids\": class_ids,\n",
    "                    \"scores\": scores,\n",
    "                    \"object\": max_object\n",
    "                }\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def clf_phone(self, img: np.array):\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        aug = self.transforms(image=img) \n",
    "        img = aug['image']\n",
    "        \n",
    "\n",
    "        img = img[np.newaxis, :, :, :]\n",
    "\n",
    "        \n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            outputs = res = self.model_phone_clf(img.float())\n",
    "            probs = torch.sigmoid(outputs) \n",
    "\n",
    "            res = probs.to(self.device).item() > 0.6\n",
    "            \n",
    "\n",
    "        return res\n",
    "    \n",
    "    def sec2minutes_sec(self, sec):\n",
    "        minutes = sec // 60\n",
    "        curr_sec = sec % 60\n",
    "        return f\"{minutes}:{curr_sec}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sec: 601\n",
      "Нарушений не выявлено\n"
     ]
    }
   ],
   "source": [
    "a.predict_video(\"9.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
